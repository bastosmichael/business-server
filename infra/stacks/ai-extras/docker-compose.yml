version: '3.8'

services:
  n8n:
    image: docker.n8n.io/n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_SECURE_COOKIE=false
      - N8N_HOST=0.0.0.0
    volumes:
      - n8n-data:/home/node/.n8n
    profiles:
      - n8n

  text-generation-webui:
    image: atinoda/text-generation-webui:default-cpu
    container_name: text-generation-webui
    restart: unless-stopped
    ports:
      - "7860:7860"
    environment:
      - CLI_ARGS=--listen
    volumes:
      - textgen-ui:/app/text-generation-webui/characters
      - textgen-ui-models:/app/text-generation-webui/models
    profiles:
      - text-generation-webui

  librechat:
    image: ghcr.io/danny-avila/librechat-dev:latest
    container_name: librechat
    restart: unless-stopped
    depends_on:
      - librechat-mongo
      - librechat-redis
      - librechat-meilisearch
    environment:
      - HOST=0.0.0.0
      - PORT=3080
      - MONGODB_URL=mongodb://librechat-mongo:27017/librechat
      - REDIS_HOST=librechat-redis
      - REDIS_PORT=6379
      - MEILI_HOST=librechat-meilisearch
      - MEILI_PORT=7700
    ports:
      - "3080:3080"
    volumes:
      - librechat-uploads:/app/uploads
      - librechat-logs:/app/logs
    profiles:
      - librechat

  librechat-mongo:
    image: mongo:7
    container_name: librechat-mongo
    restart: unless-stopped
    volumes:
      - librechat-mongo:/data/db
    profiles:
      - librechat

  librechat-redis:
    image: redis:7
    container_name: librechat-redis
    restart: unless-stopped
    command: [ "redis-server", "--save", "", "--appendonly", "no" ]
    volumes:
      - librechat-redis:/data
    profiles:
      - librechat

  librechat-meilisearch:
    image: getmeili/meilisearch:v1.10
    container_name: librechat-meilisearch
    restart: unless-stopped
    environment:
      - MEILI_ENV=production
    volumes:
      - librechat-meili:/meili_data
    profiles:
      - librechat

  comfyui:
    image: yanwk/comfyui-boot:cpu
    container_name: comfyui
    restart: unless-stopped
    ports:
      - "8188:8188"
    volumes:
      - comfyui-data:/comfyui
    profiles:
      - comfyui

  stable-diffusion-webui:
    image: siutin/stable-diffusion-webui-docker:latest-cpu
    container_name: stable-diffusion-webui
    restart: unless-stopped
    ports:
      - "7861:7860"
    volumes:
      - sd-webui:/app/stable-diffusion-webui
    environment:
      - COMMANDLINE_ARGS=--listen --skip-torch-cuda-test --no-half --use-cpu all
      - CLI_ARGS=--listen --skip-torch-cuda-test --no-half --use-cpu all
    command: [ "bash", "webui.sh", "--listen", "--skip-torch-cuda-test", "--no-half", "--use-cpu", "all" ]
    profiles:
      - stable-diffusion-webui

  whisper-server:
    image: rhasspy/wyoming-whisper:latest
    container_name: whisper-server
    restart: unless-stopped
    command: [ "--model", "tiny-int8", "--language", "en" ]
    ports:
      - "10300:10300"
    volumes:
      - whisper-models:/data
    profiles:
      - whisper-server

  whisperx:
    image: ghcr.io/sanchk/whisperx-api:latest
    container_name: whisperx
    restart: unless-stopped
    environment:
      - PORT=9001
      - WHISPER_MODEL=small
    ports:
      - "9001:9001"
    volumes:
      - whisperx-models:/root/.cache/whisperx
    profiles:
      - whisperx

  piper-tts:
    image: rhasspy/wyoming-piper:latest
    container_name: piper-tts
    restart: unless-stopped
    command: [ "--voice", "en-us-lessac-medium", "--uri", "0.0.0.0:10200" ]
    ports:
      - "10200:10200"
    volumes:
      - piper-voices:/data
    profiles:
      - piper-tts

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    profiles:
      - qdrant

  milvus:
    image: milvusdb/milvus:latest
    container_name: milvus
    restart: unless-stopped
    command: [ "milvus", "run", "standalone" ]
    ports:
      - "19530:19530"
      - "9091:9091"
    volumes:
      - milvus-data:/var/lib/milvus
    profiles:
      - milvus

  langgraph-studio:
    image: ghcr.io/langchain-ai/langgraph-studio:latest
    container_name: langgraph-studio
    restart: unless-stopped
    environment:
      - PORT=8123
      - LANGGRAPH_ENABLE_OLLAMA=true
      - LANGGRAPH_OLLAMA_URL=http://ollama:11434
    ports:
      - "8123:8123"
    volumes:
      - langgraph-projects:/workspace
    profiles:
      - langgraph-studio

  crewai-orchestrator:
    image: ghcr.io/joaomdmoura/crewai-server:latest
    container_name: crewai-orchestrator
    restart: unless-stopped
    environment:
      - PORT=8001
    ports:
      - "8001:8001"
    volumes:
      - crewai-data:/app/data
    profiles:
      - crewai

volumes:
  n8n-data:
  textgen-ui:
  textgen-ui-models:
  librechat-uploads:
  librechat-logs:
  librechat-mongo:
  librechat-redis:
  librechat-meili:
  comfyui-data:
  sd-webui:
  whisper-models:
  whisperx-models:
  piper-voices:
  qdrant-data:
  milvus-data:
  langgraph-projects:
  crewai-data:
